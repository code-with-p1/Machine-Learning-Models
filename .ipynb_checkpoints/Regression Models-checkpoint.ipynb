{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7385980-5655-4e78-95c9-4126430fad73",
   "metadata": {},
   "source": [
    "### Setup and Common Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79baef5d-cb1e-41e6-b5e2-25441a18b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Import Datasets\n",
    "from sklearn.datasets import load_diabetes, fetch_california_housing, make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "093a6a95-20d1-4f77-bd71-5106dec62709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to quickly evaluate a model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    # return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86db5dc-72a8-4035-a6f0-3fa5858f1d75",
   "metadata": {},
   "source": [
    "### Model-Specific Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0595bf56-6f95-4812-90a6-4229db1a616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Dataset 1 - load_diabetes()\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "dataset_name = \"Diabetes\"\n",
    "\n",
    "# Option B: Dataset 2 - fetch_california_housing()\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "dataset_name = \"California Housing\"\n",
    "\n",
    "# Option C: Dataset 3 - make_regression()\n",
    "X, y = make_regression(n_samples=1000, n_features=5, noise=0.1, random_state=42)\n",
    "dataset_name = \"Synthetic Regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350afa80-f663-4483-a3ba-f01b586b9b16",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef24d7b-0a0a-4065-bbb5-50c711af67c3",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b35bccb-5da2-41f1-8ba1-cdeebc683262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "MSE: 2900.1936\n",
      "R2 Score: 0.4526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load data (Choose one from Option A, B, or C above)\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create, train, and evaluate the model\n",
    "print(\"Linear Regression:\")\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2daf92-ac3b-435c-a0ee-61af38623812",
   "metadata": {},
   "source": [
    "### 2. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "093b51cd-bcec-4e97-8738-8265b0aaf2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression:\n",
      "MSE: 3077.4159\n",
      "R2 Score: 0.4192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Split data (using the same X, y from above)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create, train, and evaluate the model\n",
    "print(\"Ridge Regression:\")\n",
    "model = Ridge(alpha=1.0) # alpha is the regularization strength\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ddadb-7c4b-4ad2-8931-1b992fd7b17d",
   "metadata": {},
   "source": [
    "### 3. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0c67b6-1d14-4c4f-adb9-18aa9f86f95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression:\n",
      "MSE: 2798.1935\n",
      "R2 Score: 0.4719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create, train, and evaluate the model\n",
    "print(\"Lasso Regression:\")\n",
    "model = Lasso(alpha=0.1) # alpha is the regularization strength\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70b5e2-1f5b-4a96-bf3d-936ef19c396e",
   "metadata": {},
   "source": [
    "### 4. Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9666a49f-8703-4e62-be00-92c89b5af164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regressor (SVR):\n",
      "MSE: 4332.7385\n",
      "R2 Score: 0.1822\n"
     ]
    }
   ],
   "source": [
    "# Note: SVMs often benefit from feature scaling.\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that scales the data then applies SVR\n",
    "print(\"Support Vector Regressor (SVR):\")\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR(kernel='rbf', C=1.0)) # 'rbf' kernel is common for non-linear problems\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1035851-9aef-41ea-a6b6-9613186d8ed7",
   "metadata": {},
   "source": [
    "### 5. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78a6d829-af24-43ff-90b1-f27484e9e5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor:\n",
      "MSE: 3568.9653\n",
      "R2 Score: 0.3264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create, train, and evaluate the model\n",
    "print(\"Decision Tree Regressor:\")\n",
    "model = DecisionTreeRegressor(max_depth=4, random_state=42) # Limiting depth prevents overfitting\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83460096-0fc5-44a8-b94c-38e03e5507b6",
   "metadata": {},
   "source": [
    "### 6. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3655cc1c-73d7-4d5c-b535-76d39c4ccac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor:\n",
      "MSE: 2952.0106\n",
      "R2 Score: 0.4428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create, train, and evaluate the model\n",
    "print(\"Random Forest Regressor:\")\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42) # n_estimators = number of trees\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6862109c-383b-4765-9556-dac78cd80925",
   "metadata": {},
   "source": [
    "### 7. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e0048f1-7ff5-4848-91c8-aba8cf808408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor:\n",
      "MSE: 2898.4367\n",
      "R2 Score: 0.4529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create, train, and evaluate the model\n",
    "print(\"Gradient Boosting Regressor:\")\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d85bb3-9da9-4890-8615-8f7af8a77506",
   "metadata": {},
   "source": [
    "### 8. K-Nearest Neighbors Regressor (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e39d5ffa-8b8e-413b-a5de-30d5c89f40f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Regressor (KNN):\n",
      "MSE: 3047.4499\n",
      "R2 Score: 0.4248\n"
     ]
    }
   ],
   "source": [
    "# Note: KNN also benefits greatly from feature scaling.\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that scales the data then applies KNN\n",
    "print(\"K-Nearest Neighbors Regressor (KNN):\")\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=5)) # n_neighbors is the 'k' value\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78dd18-f76c-4fae-b16b-3bcec3afc795",
   "metadata": {},
   "source": [
    "### Complete Example Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019b7c1-9b16-4d6e-b4fe-14e43cba53ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Diabetes Dataset:\n",
      "  MSE: 2900.1936, R2: 0.4526\n",
      "California Housing Dataset:\n",
      "  MSE: 0.5559, R2: 0.5758\n",
      "Synthetic Dataset:\n",
      "  MSE: 0.0111, R2: 1.0000\n",
      "**************************************************\n",
      "Ridge Regression\n",
      "Diabetes Dataset:\n",
      "  MSE: 3077.4159, R2: 0.4192\n",
      "California Housing Dataset:\n",
      "  MSE: 0.5558, R2: 0.5759\n",
      "Synthetic Dataset:\n",
      "  MSE: 0.0179, R2: 1.0000\n",
      "**************************************************\n",
      "Lasso Regression\n",
      "Diabetes Dataset:\n",
      "  MSE: 2798.1935, R2: 0.4719\n",
      "California Housing Dataset:\n",
      "  MSE: 0.6135, R2: 0.5318\n",
      "Synthetic Dataset:\n",
      "  MSE: 0.0565, R2: 1.0000\n",
      "**************************************************\n",
      "Support Vector Regressor (SVR)\n",
      "Diabetes Dataset:\n",
      "  MSE: 4332.7385, R2: 0.1822\n",
      "California Housing Dataset:\n",
      "  MSE: 0.3570, R2: 0.7276\n",
      "Synthetic Dataset:\n",
      "  MSE: 1060.6264, R2: 0.7128\n",
      "**************************************************\n",
      "Decision Tree Regressor\n",
      "Diabetes Dataset:\n",
      "  MSE: 3568.9653, R2: 0.3264\n",
      "California Housing Dataset:\n",
      "  MSE: 0.5844, R2: 0.5540\n",
      "Synthetic Dataset:\n",
      "  MSE: 1262.0007, R2: 0.6582\n",
      "**************************************************\n",
      "Random Forest Regressor\n",
      "Diabetes Dataset:\n",
      "  MSE: 2952.0106, R2: 0.4428\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes, fetch_california_housing, make_regression\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(f\"  MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "# Define the datasets\n",
    "datasets = {\n",
    "    \"Diabetes\": load_diabetes(),\n",
    "    \"California Housing\": fetch_california_housing(),\n",
    "    \"Synthetic\": make_regression(n_samples=1000, n_features=5, noise=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "all_models = {}\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "all_models.update({'Linear Regression' : model})\n",
    "\n",
    "model = Ridge(alpha=1.0) # alpha is the regularization strength\n",
    "all_models.update({'Ridge Regression' : model})\n",
    "\n",
    "model = Lasso(alpha=0.1) # alpha is the regularization strength\n",
    "all_models.update({'Lasso Regression' : model})\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR(kernel='rbf', C=1.0)) # 'rbf' kernel is common for non-linear problems\n",
    "])\n",
    "all_models.update({'Support Vector Regressor (SVR)' : model})\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=4, random_state=42) # Limiting depth prevents overfitting\n",
    "all_models.update({'Decision Tree Regressor' : model})\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42) # n_estimators = number of trees\n",
    "all_models.update({'Random Forest Regressor' : model})\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "all_models.update({'Gradient Boosting Regressor' : model})\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor(n_neighbors=5)) # n_neighbors is the 'k' value\n",
    "])\n",
    "all_models.update({'K-Nearest Neighbors Regressor (KNN)' : model})\n",
    "\n",
    "# Train and evaluate on each dataset\n",
    "for model_name, model in all_models.items(): \n",
    "    print(f\"{model_name}\")\n",
    "    for name, data in datasets.items():\n",
    "        if name == \"Synthetic\":\n",
    "            X, y = data\n",
    "        else:\n",
    "            X, y = data.data, data.target\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"{name} Dataset:\")\n",
    "        evaluate_model(model, X_test, y_test)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "560fdc45-44e1-4407-855c-d8748b24de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance:\n",
      "\n",
      "Diabetes Dataset:\n",
      "  MSE: 2900.1936, R2: 0.4526\n",
      "  Making new predictions on sample data:\n",
      "    Sample 1: Actual = 219.00, Predicted = 139.55\n",
      "    Sample 2: Actual = 70.00, Predicted = 179.52\n",
      "    Sample 3: Actual = 202.00, Predicted = 134.04\n",
      "  Model coefficients: [  37.90402135 -241.96436231  542.42875852]...\n",
      "  Model intercept: 151.35\n",
      "--------------------------------------------------\n",
      "California Housing Dataset:\n",
      "  MSE: 0.5559, R2: 0.5758\n",
      "  Making new predictions on sample data:\n",
      "    Sample 1: Actual = 0.48, Predicted = 0.72\n",
      "    Sample 2: Actual = 0.46, Predicted = 1.76\n",
      "    Sample 3: Actual = 5.00, Predicted = 2.71\n",
      "--------------------------------------------------\n",
      "Synthetic Dataset:\n",
      "  MSE: 0.0111, R2: 1.0000\n",
      "  Making new predictions on sample data:\n",
      "    Sample 1: Actual = -54.69, Predicted = -54.75\n",
      "    Sample 2: Actual = -64.36, Predicted = -64.43\n",
      "    Sample 3: Actual = 52.88, Predicted = 52.92\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- COMPLETE EXAMPLE: Linear Regression on all 3 datasets ---\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes, fetch_california_housing, make_regression\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(f\"  MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
    "    return predictions\n",
    "\n",
    "# Define the datasets\n",
    "datasets = {\n",
    "    \"Diabetes\": load_diabetes(),\n",
    "    \"California Housing\": fetch_california_housing(),\n",
    "    \"Synthetic\": make_regression(n_samples=1000, n_features=5, noise=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train and evaluate on each dataset\n",
    "print(\"Linear Regression Performance:\\n\")\n",
    "all_predictions = {}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    if name == \"Synthetic\":\n",
    "        X, y = data\n",
    "    else:\n",
    "        X, y = data.data, data.target\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"{name} Dataset:\")\n",
    "    predictions = evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # Store predictions for demonstration\n",
    "    all_predictions[name] = predictions\n",
    "    \n",
    "    # --- NEW PREDICTION CODE ---\n",
    "    print(\"  Making new predictions on sample data:\")\n",
    "    \n",
    "    # Create some sample data points for prediction (using the first few test samples)\n",
    "    sample_X = X_test[:3]  # Take first 3 samples from test set\n",
    "    \n",
    "    # Make predictions\n",
    "    sample_predictions = model.predict(sample_X)\n",
    "    \n",
    "    # Display actual vs predicted values\n",
    "    for i, (actual, predicted) in enumerate(zip(y_test[:3], sample_predictions)):\n",
    "        print(f\"    Sample {i+1}: Actual = {actual:.2f}, Predicted = {predicted:.2f}\")\n",
    "    \n",
    "    # Show model coefficients and intercept for insight\n",
    "    if name == \"Diabetes\":  # Show this only for one dataset to avoid repetition\n",
    "        print(f\"  Model coefficients: {model.coef_[:3]}...\")  # Show first 3 coefficients\n",
    "        print(f\"  Model intercept: {model.intercept_:.2f}\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9686724d-5575-4488-a436-d2ef7eeece91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MAKING PREDICTIONS ON NEW SYNTHETIC DATA\n",
      "============================================================\n",
      "New synthetic data predictions:\n",
      "  Sample 1: Features = [ 0.5 -1.2  0.8  0.3 -0.5], Predicted = -29.60\n",
      "  Sample 2: Features = [-0.8  1.5 -0.2  0.9  0.1], Predicted = 67.01\n",
      "  Sample 3: Features = [ 1.2 -0.3  0.4 -0.7  0.6], Predicted = 21.32\n",
      "\n",
      "Model performance on synthetic test data:\n",
      "  MSE: 0.0111\n",
      "  R2 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# --- Additional demonstration: Making predictions on completely new data ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MAKING PREDICTIONS ON NEW SYNTHETIC DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate some completely new data for the synthetic dataset case\n",
    "new_synthetic_data = np.array([\n",
    "    [0.5, -1.2, 0.8, 0.3, -0.5],   # Sample 1\n",
    "    [-0.8, 1.5, -0.2, 0.9, 0.1],   # Sample 2\n",
    "    [1.2, -0.3, 0.4, -0.7, 0.6]    # Sample 3\n",
    "])\n",
    "\n",
    "# We need to retrain on the synthetic dataset specifically\n",
    "X_synth, y_synth = make_regression(n_samples=1000, n_features=5, noise=0.1, random_state=42)\n",
    "X_train_synth, X_test_synth, y_train_synth, y_test_synth = train_test_split(X_synth, y_synth, test_size=0.2, random_state=42)\n",
    "\n",
    "model_synth = LinearRegression()\n",
    "model_synth.fit(X_train_synth, y_train_synth)\n",
    "\n",
    "# Make predictions on the new data\n",
    "new_predictions = model_synth.predict(new_synthetic_data)\n",
    "\n",
    "print(\"New synthetic data predictions:\")\n",
    "for i, (features, prediction) in enumerate(zip(new_synthetic_data, new_predictions)):\n",
    "    print(f\"  Sample {i+1}: Features = {features}, Predicted = {prediction:.2f}\")\n",
    "\n",
    "# Show what the model learned\n",
    "print(f\"\\nModel performance on synthetic test data:\")\n",
    "synth_test_pred = model_synth.predict(X_test_synth)\n",
    "print(f\"  MSE: {mean_squared_error(y_test_synth, synth_test_pred):.4f}\")\n",
    "print(f\"  R2 Score: {r2_score(y_test_synth, synth_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eba0d7-11b3-4b1d-9edd-47506400c1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
